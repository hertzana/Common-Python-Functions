{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonly Used Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all rows that have missing values\n",
    "data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace missing values \n",
    "\n",
    "data['LotFrontage'].fillna(0, inplace=True) # replace missing values with 0\n",
    "data['MasVnrType'].fillna(\"None\", inplace=True)  # Fill missing values for MasVnrType with \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count up total missing values for each var\n",
    "data.isnull().sum()\n",
    "\n",
    "# Find total number of missing values in data\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For rows where \"Electrical\" variable is null, are there any other var's that contain null values?\n",
    "np.unique(data[data['Electrical'].isnull()==True].isnull().any(axis=0).tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct data quality issue: Replace MasVnrArea with 0 when MasVnrType is None\n",
    "data.loc[(data['MasVnrType'] == \"None\") & (data['MasVnrArea']!=0), 'MasVnrArea'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new variables\n",
    "data['HasBsmt'] = 1\n",
    "data.loc[data['BsmtCond'].isnull(), 'HasBsmt'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conditional Replacing\n",
    "data.loc[data['latitude']==-2e-08, 'latitude'] = np.mean(data[data['latitude']!=-2e-08]['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using replace function\n",
    "data['CentralAir'] = data['CentralAir'].replace(['N', 'Y'], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionally Drop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows where BsmtFinType2 is \"unfinished\" and where BsmtExposure is \"null\"\n",
    "data = data.drop(data.index[np.where((data['BsmtFinType2']=='Unf') & (data['BsmtExposure'].isnull()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows where BsmtUnfSF is greater than 0 and either BsmtExposure is null or BsmtFinType2 is null\n",
    "data = data.drop(data.index[np.where((data['BsmtUnfSF']>0) & (data['BsmtExposure'].isnull() | data['BsmtFinType2'].isnull()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Values\n",
    "\n",
    "# what are the different housing types when Masonry Type is none\n",
    "data[data['MasVnrType']=='None']['House Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at data variables when the condition for another variables is true\n",
    "data[data['BsmtExposure'].isnull()==True][['BsmtQual', 'BsmtCond', 'BsmtFinSF1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find number of unique values in a column\n",
    "len(data['funder'].value_counts().index.unique()) # Find number of funders\n",
    "\n",
    "# View sorted values\n",
    "sorted(data['latitude'].value_counts().index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change value to date time\n",
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
    "\n",
    "# Extract month / year from date time\n",
    "data['month-year'] = data['date_recorded'].map(lambda x: str(x.year) +\"-\"+str(x.month))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration - Graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find correlations\n",
    "corr_all = data.corr(method='pearson')\n",
    "corrs2 = corr_all.ix[-1][:-1]\n",
    "corrs2_dict = corrs2.to_dict()\n",
    "corrs2_dict\n",
    "\n",
    "# Reorder by level of correlation\n",
    "print(\"FEATURE \\tCORRELATION\")\n",
    "for attr in sorted(corrs2_dict.items(), key = lambda x: -abs(x[1])):\n",
    "    print(\"{0}: \\t{1}\".format(*attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make histogram of all data variables within the data\n",
    "data.hist(figsize=(16, 20), xlabelsize = 8, ylabelsize = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ordered Encoding\n",
    "\n",
    "# Encode Exterior Quality with the following as the quality order\n",
    "overallqual = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "data.ExterQual= data.ExterQual.astype(\"category\", ordered=True, categories=overallqual).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "varsdf = pd.get_dummies(varsdf, columns=['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', \n",
    "                                            'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "                                            'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation',\n",
    "                                            'Heating', 'Functional', 'GarageType', \n",
    "                                            'GarageFinish', 'PavedDrive', 'SaleType', 'Electrical', 'SaleCondition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_org = pd.merge(indep_vars, outcome, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take log to normalize variable\n",
    "data['SalePrice'] = np.log1p(data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at skew\n",
    "stats.skew(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(scale_df1)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns = cont_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate Data - combine columns\n",
    "stand_df = pd.concat([scaled_df, varsdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using robust scaling\n",
    "scaler = preprocessing.RobustScaler()\n",
    "\n",
    "varsdf = pd.DataFrame(data[['amount_tsh', 'gps_height']])\n",
    "\n",
    "z = scaler.fit_transform(varsdf)\n",
    "\n",
    "amount_tsh_rob = []\n",
    "gps_height = []\n",
    "for x in range(len(z)):\n",
    "    amount_tsh_rob.append(z[x][0])\n",
    "    gps_height.append(z[x][1])\n",
    "\n",
    "amount_tsh_rob = pd.Series(amount_tsh_rob)\n",
    "gps_height = pd.Series(gps_height)\n",
    "\n",
    "plt.scatter(amount_tsh_rob, gps_height)\n",
    "plt.scatter(data['amount_tsh'], data['gps_height'])\n",
    "\n",
    "# first store original index\n",
    "index_orig = data.index # type index\n",
    "datacopy = data.copy()\n",
    "# Then reindex\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data['amount_tsh_rob'] = amount_tsh_rob\n",
    "data['gps_height_rob'] = gps_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "religious = ['[M,m].*si*l[ie][mus]+', '[C,c]hur[ch]+', '[S,s]ain[ts]', '[C,c].*rist[ia]+[ns]+', '[D,d]ioce[se]*', \n",
    "             '[Aa]nglican', '[Mm]ethodist', '[Mm]i+s+i+on+ar', '[Is]lam', 'Neemia Mission', '^Rc.*', '[C,c]ath.*ic', \n",
    "             '^[R,r]oman.*', 'Isla$', '[Bb].ptist', '^Missio$']\n",
    "\n",
    "# If the string matches a logic in the above list, then replace funder type var with value \"Private Company\"\n",
    "if re.search(\"|\".join(relgious), i):\n",
    "        data.loc[data['funder']==i, 'funder_type'] = \"Private Company\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_trans.to_csv(\"Ames_Normalized.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
